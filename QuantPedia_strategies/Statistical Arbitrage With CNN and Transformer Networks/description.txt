Statistical arbitrage encompasses a class of strategies that exploits short-term price differences between assets that are hypothesized to move together based on some measure of similarity. Generally, the strategy bets on the mean-reverting behavior of similar assets when they move out of their typical spread defined by a model. In this paper, Ordonez et al. propose a novel approach that leverages the modelling of residual tradable portfolios from factor models such as the Fama French model or PCA and powerful deep learning techniques for signal extraction and allocation. This provides a theoretical ground for explaining an approach that entails estimating nonlinear relationships that map a local pattern into a time-series signal while retaining a relatively high level of interpretability. The authors propose a filter approach to the problem combined with the convolution of the price series and pattern extraction using the transformer network, allowing them to detect an arbitrage signal. In this context, the transformer network detects global patterns from the locally estimated filters by the CNN. It acts as an add-on model that projects the local patterns onto the time-series with respective loadings onto each detected local pattern. The last layer of the analysis then maps the optimal trading allocation based on a mean-variance specification that allows for the learning of the signals that maximizes or minimizes the return or the risk of the strategy. Testing this on the large-cap U.S. equity stocks, this approach proves that even when including a conservative turnover model, there is still a high level of potential arbitrage profits to be exploited in the market, albeit coming at the cost of implementing a high-frequency strategy.

Fundamental reason
The markets are a price-setting mechanism that ensures that supply and demand for a particular security is matched, and so it is the microstructure that determines the speed and efficiency of convergence to the fair price. Arbitrage trading exploits short-term price deviations in order to correct for mispricing in the market at the cost of higher trading volumes. The Machine Learning approach is not different in this sense as it is trained to detect potential signals. Trading frictions are often the problem for such a strategy (Sharpe ratio larger than 3 without costs), but the authors show that despite that such an approach comes at a cost, the Sharpe ratio still exhibits meaningful results. One problem that was identified, however, was the presence of large short-selling positions, and so a suitable constraint should be enforced when considering such an approach. The uniqueness of this approach lies in the ability to learn asymmetric responses to market regimes, such as learning to act more rapidly in downtrends and relatively fast in an uptrend which is hard to replicate with a standard parametric approach such as FFT or Ornstein-Uhlenbeck. The paper also tests for this by including these ‘standard’ approaches to the stat arb problem as benchmarks. In addition, the approach seems to be very robust to hyperparameter tuning, suggesting strong conviction in the arbitrage phenomena.

Simple trading strategy
The model is tested on the most liquid stocks in the U.S. equity market whose market capitalization in the previous month was larger than 1bps of the total market cap at that previous month. This leaves approximately 550 stocks that are roughly comparable to the S&P 500 constituents. Data is collected from January 1978 through December 2016 and split in the following way. The first sample of January 1978 through January 1998 is reserved for estimation factor models that yield residuals for the period of 1998 to 2016. These residuals constitute tradable portfolios that trade on a daily frequency at the close and provide further input for the subsequent models. In addition to returns, the CRSP/Compustat database is used for extracting accounting variables and firm-specific features, as in Chen et al. 2019. A rolling window estimation is conducted to obtain daily residuals from the Instrumented PCA model that conditions the estimation of the latent factors on the firm-specific features. The optimal number of PC’s for the model is five, after which the performance plateaus. Given these residuals, the trading signal is estimated on a rolling window to test the out-of-sample performance. Then a two-layer Convolutional Neural Network with eight local convolution filters applied on a window of two days is estimated on the prices. The output of this network is fed into a transformer network with four attention heads that detects the global patterns using the convoluted price series and constructs the arbitrage trading signals. The output of this network – the global pattern projection – is then fed into a time-wise feedforward network allocation function that maps the pattern into allocations using a mean-variance identification. The main results use a rolling window of 1000 to estimate the deep learning model framework, and it is retrained every 125 days. The strategy trades all of the residuals that are mapped into the positions of original stocks, and the portfolio is fully invested with no leverage.

Hedge for stocks during bear markets
Yes - The strategy is, by definition, a hedge for the market beta given the fact that the residual process is used for estimating the arbitrage signals. The factor model removes the linear association from the residual process, making the trading signals orthogonal. This is also confirmed by the fact that the R-squared is very low for the returns regressed onto the Fama-French 8 factors. Hence, it is not only a good hedge for the market beta but also for the other traditional risk factors.