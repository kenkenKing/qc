Climate change and the risks associated with it have been recently scrutinized for the possible effects on the pricing of assets as financial markets start to adopt a ‘greener’ attitude towards investments. Though topics such as the effect of carbon footprint have been studied under the assumption that the investors pay attention to changes in such factors, a novel approach is proposed in this paper using an unsupervised learning procedure applied to textual data. The paper develops an intuitive number of factors that are tested against the hypothesis that they do not affect the pricing kernel using the Latent Dirichlet Allocation algorithm. Using news data, the words are collected into so-called topics, which form an output of the K most important topics the model is estimated on. The model is a Bayesian model since the generative process of the algorithm estimates the conditional distribution of the probability a topic is found for each word in the document using some sampling technique. In this case, the Gibbs sampler is used as the authors postulate that there are efficiency benefits in terms of estimation — for more details, see the Appendix A of the paper. First used in a Biology setting, LDA is a natural candidate for datasets where there are no labels for the topics we are searching for. This allows the authors to capture the idiosyncrasies of the data, finding that there are four main topics that can potentially have a pricing implication. These are the topics of Natural Disasters, Global Warming, International Summits, and U.S. climate policy. Interestingly, the authors conclude that only the U.S. climate policy factor is priced in based on the experiments, and so we focus on this factor in this strategy description. Despite the authors’ primary focus on the risk factors concerning climate change as such, this approach is widely applicable to textual data and provides a framework that can be deployed on virtually any preprocessed dataset that is trying to model potentially important topics within.

Fundamental reason
As the authors point out, there is a high probability that a large part of the risk premium on climate change is uncorrelated to traditional risk factors established in the literature. This is quite intuitive as these typically happen exogenously. For example, a major event such as a flood triggers a large amount of news to be produced about it, and hence the investors start to pay attention to this news and possibly take these betas into account if significant. Based on this hedging motive, the decrease in such a factor signal increased risks from climate change, possibly causing a repricing in the assets that have higher loadings on these climate effects. This is also confirmed in the paper, as suggested by Table 2. Including typical factors in decomposing the return from the U.S. Climate Policy factor does not deteriorate the alpha significantly, except for mild effects from including momentum in the model. Intuitively this can be explained by a sentiment argument too, whereas tighter environmental policy would affect companies’ sentiment factor in the case of a highly correlated asset. The reasonable reaction to this type of change is shorting a stock like that, which many managers probably employ to an extent, as demonstrated in the paper.

Simple trading strategy
The universe consists of all CRSP U.S Equities with share codes 10 and 11 respectively, adjusted for delisting. This yields a sample of 4700 tradable instruments throughout the period of 2000 and 2018, from which the textual data is also extracted. This data consists of news articles written in English sourced from Thomson Reuters News Archive. These news articles are processed for corrections and filtered for unrelated news yielding a sample of 7 million articles. This dataset is then used for estimation on the LDA topic analysis. Taking in the articles and the number of unique words as inputs, the so-called textual corpus is split into topics. Then the articles are expressed as some vector of weights over these topics, which represents a unique empirical distribution over the words. For each time t, a different vector for each of the topics is featured, allowing the analysis to include a temporal difference in the topic shares. These two outputs, namely the topics themselves and the topic shares, constitute the outputs of the model. It is the latter that provides for a way to construct risk factors that are used in this paper. Intuitively, the probability that a word is found in any article is the sum of the product of each of the topics and topic shares across all of the topics. The model specifies the Bayesian prior to be Dirichlet for the probability distributions of the topics and the topic shares. Associated hyperparameters are 1/K and 1/10 for the scale and location parameters for a K number of topics. Subsequently, a Kalman filter is applied to the likelihood to estimate the posterior distribution. This distribution is simulated by the Metropolis-Hastings procedure as outlined in Appendix A. The number of topics estimated is set to be K = 25. For these 25 estimated topics, several collective themes are chosen, representing the factors that are selected to be semantically independent. This process is hard to automate, and therefore it is essential to understand the context of the analysis to successfully perform such a classification. The risk factor is constructed using the topic share for each day as estimated by the LDA. Then a time series is created by summing the topic shares of each article related to the climate change topic – in this case, the U.S. Climate Policy. Then at the end of each month in the rolling window, a risk model is estimated, and the beta with respect to the Climate Policy factor is retrieved. At the end of each month, the stocks in the sample are sorted into deciles based on this beta, and a long-short spread portfolio is formed. The stocks are value-weighted to mitigate possible size bias.

Hedge for stocks during bear markets
Not known - The paper does not include any information regarding to this topic.