The paper examines how Form 10-K filings, which are mandatory financial reports for public companies, can be analyzed to predict future stock returns. Traditional methods focusing on readability or sentiment often struggle to offer strong statistical insights. This paper introduces a new approach: creating a dictionary of predictive words using a bottom-up, data-driven process. Using lasso regularized regressions, the researchers identify specific words from 10-K filings that correlate with expected stock returns. Words like “currency,” “oil,” “research,” and “restructuring” suggest increased returns, while terms like “acquisition,” “completed,” and “derivatives” imply decreased returns. This method creates a factor model that provides statistically significant predictions for future returns, outperforming traditional sentiment-based models. The paper also explores a more flexible approach by using sparse neural networks, confirming that simpler linear models with an ℓ1 penalty are effective. Finally, the authors compare their method with a document embedding technique using BERT, finding that the bottom-up approach with word counts is more reliable in predicting stock returns. This innovative approach to dictionary construction offers a more accurate way to analyze corporate disclosures, providing valuable insights for investors and researchers interested in assessing the impact of 10-K texts on stock returns.

Fundamental reason
The paper’s functionality comes from its innovative method of analyzing Form 10-K filings to predict future stock returns. Traditional text analysis in finance often relies on predefined sentiment dictionaries, which have weak correlations with stock returns. This paper takes a different approach by constructing dictionaries from the ground up, using lasso regularized regressions to identify words in 10-K filings that correlate with expected stock returns. By focusing on specific words that indicate future returns, the paper provides a factor model that generates statistically significant predictions. Words like “currency,” “oil,” “research,” and “restructuring” suggest increased returns, while “acquisition,” “completed,” and “derivatives” suggest decreased returns. This bottom-up approach outperforms traditional sentiment-based models and even large language models like BERT. The paper’s advantage is its data-driven, predictive methodology, leading to simpler and more effective dictionaries for analyzing corporate disclosures. This approach can be used to build portfolios with higher expected returns, demonstrating the profitability of trading based on insights from Form 10-K filings.

Simple trading strategy
The paper creates three groups of text-based characteristics derived from Form 10-K filings. It begins by describing how these filings were collected and processed. The dataset includes all available Form 10-K filings from the EDGAR database, except for amendments and filings that couldn’t be linked to CRSP (Center for Research in Security Prices) data. The linkage was achieved through Compustat, using CIK (Central Index Key) identifiers, and the CRSP-Compustat link table. The sample spans January 1995 to December 2022. To prepare the filings for analysis, the text was cleaned by removing HTML tags, ASCII-encoded graphics, and non-alphabetical characters.

The paper then focuses on word counts as one method to generate firm characteristics. It calculates the raw word count for each word by counting its occurrences in a filing and then dividing by the total word count to standardize the value. Further standardization is achieved through a cross-sectional mean and standard deviation. This method concentrates on the 1,000 most frequent words, excluding stop words and adverbs. The Loughran and McDonald sentiment dictionary is used to identify sentiment-related words.

Next, the paper discusses the use of BERT (Bidirectional Encoder Representations from Transformers) to create document embeddings. This approach generates a vector representation for each Form 10-K document by segmenting it into 400-word sections and extracting a 312-dimensional vector from BERT’s final hidden layer. These embeddings are then cross-sectionally standardized for analysis. This approach serves as a comparison to the count-based method, allowing the paper to validate findings from the bottom-up dictionary approach.

Section 3 describes the methodology used to create various dictionary models for estimating expected stock returns from Form 10-K filings. It explores three distinct approaches: a bottom-up lasso-based dictionary, a top-down linear model, and a nonlinear dictionary using a neural network.

Bottom-Up Dictionary
The primary approach uses a lasso-regularized linear regression model. This model estimates the relationship between monthly stock returns and the cross-sectionally standardized word counts of the 1,000 most frequent words from the Form 10-K filings. The lasso regularization adds an ℓ1 penalty to induce sparsity, meaning only a subset of words is deemed significant in predicting stock returns. This reduces model complexity and enhances generalization. The initial model parameters are tuned using the first half of the data (1995-2007), while the second half (2008-2021) is used for out-of-sample testing.

Top-Down Dictionary
The second approach is based on the linear model proposed by Jegadeesh and Wu (2013). This model assumes a linear relationship between stock returns and a predefined set of sentiment-related words from the Loughran and McDonald (2011) sentiment dictionary. It uses ordinary least squares (OLS) to estimate the relationship between these sentiment words and expected returns. This approach contrasts with the bottom-up model by focusing specifically on sentiment-related words instead of a broader set of frequent words.

Nonlinear Bottom-Up Dictionary
The final approach uses a two-layer neural network with rectified linear unit (ReLU) activation functions to estimate a nonlinear model of expected returns. This method involves splitting the data into subgroups using random projection trees. Each subgroup is treated as a “gate” in the neural network, with parameters estimated through a regularized minimization problem. The regularization includes group lasso, lasso, and ridge penalties to encourage sparsity and prevent overfitting. The resulting model allows for more complex relationships between word counts and stock returns.

Section 4 provides empirical results for portfolios formed using different text-based methods of analyzing Form 10-K filings to predict expected stock returns. It evaluates the performance of portfolios created from bottom-up, top-down, and large language model approaches and examines factors like cumulative returns, transaction costs, and portfolio robustness.

Cumulative Returns and Portfolio Analysis: The cumulative returns for portfolios based on the bottom-up approach (lasso-regularized linear regression), top-down (sentiment-based linear regression), and large language model (BERT embeddings) are compared. The bottom-up method consistently shows strong cumulative returns and high Sharpe ratios, indicating profitability and lower risk. The neural network-based bottom-up method also tracks well with the linear lasso approach, while the large language model struggles to provide meaningful insights.

Portfolio Returns by Different Methods: Portfolios formed using the bottom-up method display higher average returns and significant positive alphas, indicating profitability even after accounting for standard factor models. The top-down method, which uses sentiment-based dictionaries, shows weaker returns and low statistical significance, suggesting a less reliable approach. The large language model method has similar results, with generally low or insignificant returns.

Bottom-Up Dictionary and Portfolio Returns: The paper explores the specific words in the bottom-up dictionary that contribute to positive and negative expected returns. Words related to financing and investments generally have a positive impact, while those associated with accounting and liabilities tend to have negative effects. This suggests that certain themes or concepts within 10-K filings can indicate a company’s future performance.

Additional Analyses: The paper also investigates other factors that might influence the reliability of the bottom-up dictionary. It finds that the relationship between the bottom-up expected returns and stocks’ actual returns is relatively persistent over time. The expected returns derived from the bottom-up dictionary remain robust even after considering transaction costs. Additionally, when comparing the bottom-up approach with 10-K readability and sentiment, the bottom-up approach shows more significant relationships with expected stock returns.

Hedge for stocks during bear markets
Not known -