Main idea of the article is to investigate the impact of financial news on equity returns and introduce a non-parametric model. This model is used to generate a sentiment signal, which is subsequently used as a predictor for short-term, single-stock equity return forecasts. The authors take the BERT model by Google and sequentially train it on financial news from Thomson Reuters (time period from 1996 to 2020). Investigation of the ability of a BERT-based language model to generate a sentiment score from financial news articles for predicting short-term equity returns was done.BERT model was modified for the specific purposes of this study, and it was found that this model is capable of extracting sentimental signal from financial news. This signal has positive correlation with asset returns. It was found that news tend to induce stronger abnormal returns on day t than fresh news, while the information of financial news is incorporated into stock prices within one day. Categorization of news articles into topics can provide information, which can be used as additional features further and this can help make more precise models and improve the model’s ability to predict future asset returns. If only data from the topic “Analyst Forecast” are considered, the most precise forecasts of future asset returns are produced. The authors of this paper concentrate on S&P 500 companies with large market capitalizations.It was discovered that financial news is quickly incorporated into asset prices. Despite of smaller size of the model created by authors, in comparison with FinBERT (Araci, 2019) and full-sized BERT model, it shows superior out-of-sample performance (Table 9). The authors believe that the high quality of the model is conditioned by combination of domain specific pre-training and their deep neural network classifier trained with symmetric cross entropy loss on large annotated financial news dataset.
Fundamental reason
The main reason for the functionality of this machine learning strategy is that the authors created and trained new model based on BERT with domain specific Thomson Reuters financial news data. The strong benefit of this model is pre-training just only on financial news data. FinNewsBERT, as the authors named their model, is the smaller version of BERT with only 18.95 million parameters (BERT has 110 million parameters). This smaller model conserves computing resources and costs while maintaining competitive accuracy. To evaluate if the extracted sentiment measure is suitable for making investment decisions, an out-of sample backtest ranging from January 2002 to January 2020 was made.

Simple trading strategy
The trading strategy is the following:
1. Forming a portfolio of stocks with positive sentiment signal (equally weighted, long only strategy).
2. Forming a long-short strategy with positive weights in stocks with positive sentiment signal and negative weight in stocks with negative sentiment signal.
The start of trading at market open and generate sentiment signals based on all news published between the market close on day t-1 at 4:00 pm and the market open on day t at 9:30 am (news window = 17.5h). Model’s ability is proved by trading strategy is implemented with the objective to generate positive alpha by making trading decisions based on the sentiment of financial news. Stocks associated with positive news are bought and stocks associated with negative news are sold.
In this paper were used two sources of data:
1. Dataset of financial news published by Refinitiv (formerly Thomson Reuters) from January 1996 to February 2020.
2. Refinitiv Datastream – downloading of daily price data of 1330 companies in the S&P 500 (same time period as the first source).
The timestamp, the language of the article, a list of topics, and, in the case of business news, company ticker codes are all assigned to each article in the financial news dataset. To extract all news articles pertaining to those 1330 S&P 500 companies, ticker codes are used. Only news stories with either the company name or the ticker code in the headline are taken into account for fine-tuning and inference. The goal is for the content of these articles to be more relevant to the associated company than other, more general news. News articles are then converted to lower case and cleaned. All numbers, punctuation marks, and brackets are removed, so only letters remain. Also, all other non-relevant data are removed. Only the last update that is published before the stock market closes is considered. This allows opening a position in the corresponding asset at the market close on the same day.
The news dataset from Thomson Reuters does not contain any labels with sentiment information, but labelled data is necessary for supervised machine learning. To obtain a large annotated dataset, the authors used Kelly et al. (2009) methodology, where sentiment annotations are derived from return data.
The model consist of three parts:
1. FinNewsBERT – generates document embeddings (CLS token) from news articles.
2. Text2Topic – categorizes news articles into pre-specified topics. Features are then combined into one feature vector.
3. Deep Neural Network (DNN) – receives the feature vector as input. Classifies news articles into the three sentiment categories positive, neutral, and negative.
The FinNewsBERT is relatively small. It has 18.95 million parameters. It is composed of six hidden layers, four attention heads an embedding size of 256 and a maximum input sequence length of 256 tokens. The vocabulary size is 30 257 words. Authors used tokenization – the splitting of words into subwords that are then converted into token-ids via a lookup table.
The model with a batch-size of 128 and a maximum sequence length of 128 tokens for 100% of the steps, was trained. As the optimizer was used Adam with β1 = 0.9, β2 = 0.999, epsilon = 1e-06 and a maximum learning rate of 1e-04 with 10,000 warm-up steps and a linear learning rate schedule. A dropout rate of 0.1 and the GELU activation function in all layers, were also implemented. Weight decay with a parameter value of 0.01 was applied. §The model was pre-trained on a maximum of 4GB. It was domain-specific financial news articles (4GB of data is used for the model trained from 1996 to 2017). This model is then fine-tuned on the labeled data set for the sentiment classification task over the same time horizon and then used for inference in the following two years, as authors state in the article. Data from January 1996 to December 2003 is used to pre-train and fine-tune the second model which is then used for inference from 2004 to 2005. This procedure is repeated until 2017. Therefore there are nine different models (model (1996 – 2001, model (1996 – 2003), model (1996 – 2005), …, (1996 – 2017)). So, fine-tuning is done by sequentially re-training the model every two years. The validation dataset consists of news articles which were published subsequent to the training period. The size of the validation set is set to 20 % of the training set size (limited to a maximum size 20,000 news articles). The validation set starts in January 2016, if the model is trained with data from January 1996 to December 2015.
t can be observed that news classified as positive (negative) is associated with large positive (negative) abnormal returns on day t (Figure 7). This indicates that FinNewsBERT is able to correctly predict the sentiment of financial news and their impact on asset returns. Investigation of the ability of the model in terms of predicting upward and down ward movements in future asset prices, was made.
The authors implement a trading strategy that goes long in assets with positive news sentiment and short in assets with negative news sentiment. Then are forming equally weighted long and long/short portfolios that are rebalanced at a daily frequency, based on the selected assets. The trading algorithm was designed in a very flexible way. It allows to examine and compare the results with different parameter settings.
Hedge for stocks during bear markets
Not known - Authors observe that the training accuracy takes about three years to recover to pre-financial crisis levels. They assume that the data during the financial crisis contains a larger fraction of mislabelled observations, which weakens the accuracy in the following periods. However, they do not further investigate whether excluding this period has benefits.